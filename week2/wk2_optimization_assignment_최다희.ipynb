{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09144413, 0.19460076, 0.73436612])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i]*parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = 1/(1+\\epsilon ^{-z})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1/(1 + np.exp(-z))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5876956435772664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) = - \\Sigma [ylogH(x) + (1-y)log(1-H(x))] $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters)\n",
    "    loss = -(y*np.log(p)+(1-y)*np.log(1-p))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = dot_product(X,parameters)\n",
    "    loss = np.power(y-y_hat, 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss/n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597541227028826"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)= -\\Sigma(y_i - \\theta^TX_i)X_ij$ \n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)= -\\Sigma(y_i - p_i)X_ij$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X,parameters)\n",
    "        gradient = -(y-y_hat)*X[j]\n",
    "    else:\n",
    "        p = logistic(X,parameters)\n",
    "        gradient = -(y-p)*X[j]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1259981103557093"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom IPython.display import Image\\n\\nImage(\"C:/Users/rhskr/Desktop/배치알고리즘_구현.png\")\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(\"C:/Users/rhskr/Desktop/배치알고리즘_구현.png\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.45980240518859, 6.09109335973812, 42.37174907456014]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "#### 설명: 배치사이즈는 몇 개의 관측치에 대한 예측을 하고, 레이블 값과 비교를 하는지를 설정하는 파라미터입니다. 만약 데이터의 크기가 100이고 배치사이즈가 100이면, 전체 데이터에 대해 모두 예측한 뒤 실제 레이블 값과 비교한 후 가중치 갱신을 합니다. 배치사이즈가 10이면 10개 데이터에 대해 예측한 뒤 실제 레이블 값과 비교하며 가중치 갱신도 10번 발생합니다. batch_idx함수를 살펴보면 데이터의 개수를 설정한 배치사이즈로 나누어 n / batch_size 만큼의 데이터 셋을 만드는 걸 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "    \n",
    "    parameters -= gradients   # parameter update\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08671135, 0.19378463, 0.72871154])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch: 반복횟수\n",
    "- num_epoch: 총 학습 횟수\n",
    "<br>\n",
    "\n",
    "BGD: 데이터가 1000개 있을 때 모든 데이터에 대하여 각각 Loss function을 계산하고, 그들의 기댓값을 오차(ε)로 하고, 그 오차를 최소화시키는 방향으로 weight들을 업데이트합니다.\n",
    "\n",
    "SGD: 데이터가 1000개가 있을 때 각 데이터에 대하여 Loss function을 계산하고, 그 함수를 최소화하는 방향으로 W를 업데이트합니다. 즉 BGD는 1000개의 데이터 모두를 고려한다고 하면, SGD는 1개의 데이터만 고려하게 됩니다.\n",
    "\n",
    "MGD: 10000개의 데이터가 존재하면 100개씩 미니 배치를 만들어서 각 100개씩 BGD 방식으로 W를 갱신합니다.\n",
    "\n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "\n",
    "batch_size=1 -> \"SGD\"  \n",
    "\n",
    "batch_size=k -> \"MGD\"  \n",
    "\n",
    "batch_size=whole -> \"BGD\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, \n",
    "                     tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, batch_size)\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, batch_size)\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.951766173847354  params: [0.68409277 0.40409609 0.40955584]  gradients: [0.03720168495327555, 0.0026666045661156556, 0.023997036798989735]\n",
      "epoch: 100  loss: 0.4564849926879393  params: [-0.79594647  0.85683125 -0.7729132 ]  gradients: [0.004312669017642411, -0.006215694143351925, 0.006560742802779388]\n",
      "epoch: 200  loss: 0.39321048413220877  params: [-1.0297524   1.38911177 -1.3054718 ]  gradients: [0.0013693672302414496, -0.004511500783895883, 0.004417364261753836]\n",
      "epoch: 300  loss: 0.3622252768919101  params: [-1.13766865  1.77900338 -1.68545803]  gradients: [0.0008977249331368652, -0.003387276197148297, 0.0032878789536559634]\n",
      "epoch: 400  loss: 0.3440869463297294  params: [-1.21772756  2.07906016 -1.97578651]  gradients: [0.0007226341855437951, -0.002670247950495687, 0.0025754472047525845]\n",
      "epoch: 500  loss: 0.3324497555373587  params: [-1.28398166  2.31992859 -2.20747874]  gradients: [0.0006094046697589951, -0.002180417099892874, 0.0020917700240575252]\n",
      "epoch: 600  loss: 0.3245094850667742  params: [-1.34037689  2.5191913  -2.39820683]  gradients: [0.000522786358221891, -0.001826004081093548, 0.0017438977352042745]\n",
      "epoch: 700  loss: 0.3188471149515355  params: [-1.38903689  2.68767903 -2.55880838]  gradients: [0.0004535597988234103, -0.0015580653869396051, 0.001482330778594778]\n",
      "epoch: 800  loss: 0.31467336734662327  params: [-1.43145244  2.83250243 -2.69636394]  gradients: [0.00039716948607789826, -0.001348572616340767, 0.0012788162722319036]\n",
      "epoch: 900  loss: 0.31151705277350206  params: [-1.468745    2.95857627 -2.81574458]  gradients: [0.00035057678281215, -0.0011804187349160283, 0.0011161773045965664]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.50146629,  3.06839769, -2.9194598 ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train,  batch_size = 150) # batch_size=whole -> \"BGD\"\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "x0H5tnauLMa-",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.2799509707470732  params: [-0.86107715  1.12507103 -1.25227557]  gradients: [0.02526267641677254, 0.013747972668951423, 0.017774585239667077]\n",
      "epoch: 100  loss: 0.07736669873488512  params: [-1.93032584  4.17501997 -4.06769156]  gradients: [0.007538541900643538, 0.00410248171270497, 0.005304048287885604]\n",
      "epoch: 200  loss: 0.07736266552029206  params: [-1.9303681   4.1751431  -4.06780374]  gradients: [0.007538159521686478, 0.004102273621710804, 0.005303779249591561]\n",
      "epoch: 300  loss: 0.07736266518361704  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489767116, 0.0041022736043402576, 0.0053037792271333935]\n",
      "epoch: 400  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 500  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 600  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 700  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 800  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 900  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9303681 ,  4.17514311, -4.06780375])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, batch_size = 1) # batch_size=1 -> \"SGD\"\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.2804983016762954  params: [-0.17423892  0.07649642  0.20237139]  gradients: [0.013384434295485054, 0.012321896520735088, 0.01781059339399712]\n",
      "epoch: 100  loss: 0.08247168063697044  params: [-1.48409525  2.99607354 -2.85893841]  gradients: [0.0033595154786327398, 0.004766857273047442, 0.006126111281204227]\n",
      "epoch: 200  loss: 0.07086156853657927  params: [-1.6856526   3.65925361 -3.48041799]  gradients: [0.0031850323970032722, 0.004659058206632827, 0.0055828979031231594]\n",
      "epoch: 300  loss: 0.06678606195507587  params: [-1.77420829  3.94657269 -3.74700496]  gradients: [0.003141274233669464, 0.004629301130504224, 0.005396907383814544]\n",
      "epoch: 400  loss: 0.06493970104069724  params: [-1.81851915  4.08972806 -3.87926058]  gradients: [0.0031249285920169623, 0.004617628612037784, 0.005313724751103241]\n",
      "epoch: 500  loss: 0.06401241279007137  params: [-1.84191674  4.16517678 -3.94881663]  gradients: [0.0031175795845457908, 0.004612233776878308, 0.0052722301076391954]\n",
      "epoch: 600  loss: 0.06352308780379545  params: [-1.85459608  4.20602464 -3.98643226]  gradients: [0.0031139385906263166, 0.004609518591072515, 0.005250413450698201]\n",
      "epoch: 700  loss: 0.06325819099421305  params: [-1.86155989  4.22844817 -4.00706904]  gradients: [0.003112036612055122, 0.004608087531813351, 0.005238626592559243]\n",
      "epoch: 800  loss: 0.06311281332802587  params: [-1.86541216  4.24084919 -4.01847815]  gradients: [0.003111013532354675, 0.0046073138818567535, 0.005232165014583539]\n",
      "epoch: 900  loss: 0.06303243102159925  params: [-1.86755154  4.24773516 -4.0248122 ]  gradients: [0.0031104541813488404, 0.004606889706788095, 0.005228594467901836]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.86873344,  4.25153901, -4.0283108 ])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, batch_size = 16 ) # batch_size=k -> \"MGD\"\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss값을 비교해 보면 \n",
    "\n",
    "bgd => 0.311\n",
    "\n",
    "sgd => 0.077\n",
    "\n",
    "mgd => 0.063\n",
    "\n",
    "로 mgd가 제일 좋았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 4,  6]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33012946, 2.92229723])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.32062427677495997  params: [1.31220102 0.61042915]  gradients: [-0.01349388728462888, -0.008751100526836468]\n",
      "epoch: 100  loss: 0.21784786761505326  params: [0.34641952 2.92990258]  gradients: [-0.010815402938854126, -0.005846177487715833]\n",
      "epoch: 200  loss: 0.21782301256052236  params: [0.34423344 2.93413816]  gradients: [-0.010827099785333113, -0.00584826758435105]\n",
      "epoch: 300  loss: 0.21782296554839983  params: [0.34422928 2.93414623]  gradients: [-0.01082712205822535, -0.005848271564269673]\n",
      "epoch: 400  loss: 0.21782296545888152  params: [0.34422927 2.93414624]  gradients: [-0.010827122100636931, -0.005848271571848152]\n",
      "epoch: 500  loss: 0.21782296545871105  params: [0.34422927 2.93414624]  gradients: [-0.010827122100717687, -0.00584827157186258]\n",
      "epoch: 600  loss: 0.21782296545871074  params: [0.34422927 2.93414624]  gradients: [-0.010827122100717831, -0.005848271571862608]\n",
      "epoch: 700  loss: 0.21782296545871074  params: [0.34422927 2.93414624]  gradients: [-0.010827122100717831, -0.005848271571862608]\n",
      "epoch: 800  loss: 0.21782296545871074  params: [0.34422927 2.93414624]  gradients: [-0.010827122100717831, -0.005848271571862608]\n",
      "epoch: 900  loss: 0.21782296545871074  params: [0.34422927 2.93414624]  gradients: [-0.010827122100717831, -0.005848271571862608]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.34422927, 2.93414624])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, learning_rate=0.1, model = 'linear')\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
