{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프레임워크와 라이브러리의 차이는 흐름에 대한 제어 권한이 어디에 있는가 이다. 프레임워크는 전체적인 흐름을 자체적으로 가지고 있으며, 프로그래머가 그 안에 필요한 코드를 작성하는 반면 라이브러리는 사용자가 흐름에 대한 제어를 하며 필요한 상황에 가져다 쓰는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 지도학습, 비지도학습, 강화학습을 통해 학습 방법을 스스로 개선하여 문제를 해결하는 인공지능의 한 분야이며 딥러닝은 인고ㅇ신경망을 통해 학습하고 문제를 해결하는 머신러닝의 하위 개념이다. 머신러닝은 구조화된 데이터를 필요로하고 전통적인 알고리즘을 사용하는 반면 딥러닝은 신경망을 통해 대량의 비정형 데이터를 수용하도록 구축된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "# cuda 쓸 수 있으면 쓰고 아니면 cpu 씀\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(45) # 시드고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train_set = torchvision.datasets.MNIST( # MNIST 데이터 셋 불러옴\n",
    "    root = './data/MNIST', # 데이터 다운 경로\n",
    "    train = True, # training data 리턴\n",
    "    download = True, # 경로에 데이터 없을경우 다운로드 받겠다\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() # 텐서로 변환\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(# MNIST 데이터 셋 불러옴\n",
    "    root = './data/MNIST',# 데이터 다운 경로\n",
    "    train = False,# test data 리턴\n",
    "    download = True, # 경로에 데이터 없을경우 다운로드 받겠다\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()  # 텐서로 변환\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 mnist 데이터 dataloader로 데이터 로드함\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# 데이터 쉐입확인\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape # 출력시 ** torch.Size([1, 28, 28]) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # convolution layer 1 : input 텐서의 채널 수 = 1, ouput 텐서의 채널 수 = 10, 커널 사이즈 = 5\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) \n",
    "        # convolution layer 2 : input 텐서의 채널 수 = 10, ouput 텐서의 채널 수 = 20, 커널 사이즈 = 5\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        # dropout 층 : dropout 비율 0.25\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) \n",
    "        # maxpooling 층 : 커널사이즈 = 2, 스트라이드 = 2\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        # fully-Connected layer 1 : input_dim = 320, output_dim = 100 >> 100개 차원으로\n",
    "        self.fc1 = nn.Linear(320,100) \n",
    "        # fully-Connected layer 2 : input_dim = 100, output_dim= 10 >> 10개 출력\n",
    "        self.fc2 = nn.Linear(100,10) \n",
    "\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) # convolution layer 1에 relu를 씌우고 maxpool\n",
    "        x = F.relu(self.mp(self.conv2(x))) # convolution layer 2에 relu를 씌우고 maxpool\n",
    "        x = self.drop2D(x) \n",
    "        x = x.view(x.size(0), -1) # Flatten : 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼침\n",
    "        x = self.fc1(x) # fc1 레이어에 삽입\n",
    "        x = self.fc2(x) # fc2 레이어에 삽입\n",
    "        return F.log_softmax(x) # logsoftmax 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device) # 모델생성\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 손실함수로 크로스엔트로피 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # 최적화함수로 Adam 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad() # gradient 0으로 설정\n",
    "        hypothesis = model(data) # 모델을 forward pass해 결과값 저장 \n",
    "        cost = criterion(hypothesis, target) # output과 target의 loss 계산\n",
    "        cost.backward() # gradient 계산\n",
    "        optimizer.step() # 모델의 학습 파라미터 갱신\n",
    "        avg_cost += cost / len(train_loader) # loss 값을 변수에 누적하고 train_loader의 개수로 나눔 = 평균\n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()# evaluate mode로 전환 dropout 이나 batch_normalization 해제\n",
    "with torch.no_grad():# grad 해제  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1] # 출력이 분류 각각에 대한 값으로 나타나기 때문에, 가장 높은 값을 갖는 인덱스를 추출\n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item() # 예측값과 실제값이 같은지 비교\n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
